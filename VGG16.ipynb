{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/home/fundamentia/.vscode/extensions/ms-toolsai.jupyter-2022.9.1202862440/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/usr/lib/python3/dist-packages/notebook/notebookapp.py\", line 43, in <module>\n",
      "\u001b[1;31m    from jinja2 import Environment, FileSystemLoader\n",
      "\u001b[1;31m  File \"/usr/lib/python3/dist-packages/jinja2/__init__.py\", line 33, in <module>\n",
      "\u001b[1;31m    from jinja2.environment import Environment, Template\n",
      "\u001b[1;31m  File \"/usr/lib/python3/dist-packages/jinja2/environment.py\", line 15, in <module>\n",
      "\u001b[1;31m    from jinja2 import nodes\n",
      "\u001b[1;31m  File \"/usr/lib/python3/dist-packages/jinja2/nodes.py\", line 23, in <module>\n",
      "\u001b[1;31m    from jinja2.utils import Markup\n",
      "\u001b[1;31m  File \"/usr/lib/python3/dist-packages/jinja2/utils.py\", line 656, in <module>\n",
      "\u001b[1;31m    from markupsafe import Markup, escape, soft_unicode\n",
      "\u001b[1;31mImportError: cannot import name 'soft_unicode' from 'markupsafe' (/usr/local/lib/python3.8/dist-packages/markupsafe/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/home/fundamentia/.vscode/extensions/ms-toolsai.jupyter-2022.9.1202862440/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/home/fundamentia/.vscode/extensions/ms-toolsai.jupyter-2022.9.1202862440/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/home/fundamentia/.vscode/extensions/ms-toolsai.jupyter-2022.9.1202862440/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/usr/lib/python3/dist-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/home/fundamentia/python/tfm_breast_cancer_detection\" --config=/tmp/d8052c69-d62e-4d7d-9921-d75c00a42a02/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31mVea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "!pip3 install tfa-nightly\n",
    "#importacion de librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from io import BytesIO\n",
    "import timeit\n",
    "import os\n",
    "import warnings\n",
    "import statistics\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from tensorflow.python.keras.applications.efficientnet import EfficientNetB0\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "print(tf.test.is_gpu_available())\n",
    "# tf.config.experimental.set_memory_growth = True\n",
    "# %cd /home/fundamentia/Dropbox/Master/Asignaturas/Deep Learning/PRA1/archive/practica_DL_UOC_2022\n",
    "def freeze_layers(model):\n",
    "    for i in model.layers:\n",
    "        i.trainable = False\n",
    "        if isinstance(i, Model):\n",
    "            freeze_layers(i)\n",
    "    return model\n",
    "\n",
    "\n",
    "%cd /home/fundamentia/python/corpus/transformadas_640/clasificadas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el data set del fold 0\n",
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array = []\n",
    "    class_name = []\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "       \n",
    "            image_path = os.path.join(img_folder, dir1,  file)\n",
    "            image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "#             image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "#             image = np.array(image)\n",
    "#             image = image.astype('float32')\n",
    "#             image /= 255 \n",
    "            img_data_array.append(image)\n",
    "            if \"Mass\" in dir1:\n",
    "                class_name.append(1)\n",
    "            else:\n",
    "                class_name.append(0)\n",
    "    return np.array(img_data_array), np.array(class_name)\n",
    "\n",
    "labels = [\"normal\", \"abnormal\"]\n",
    "fold0_test_x, fold0_test_y = create_dataset('Fold0/Test')\n",
    "fold0_train_x, fold0_train_y = create_dataset('Fold0/Train')\n",
    "fold0_valid_x, fold0_valid_y = create_dataset('Fold0/Valid')\n",
    "\n",
    "fold0_test_y_norm = to_categorical(fold0_test_y)\n",
    "fold0_train_y_norm = to_categorical(fold0_train_y)\n",
    "fold0_valid_y_norm = to_categorical(fold0_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimesiones de entrenamiento X: (2039, 224, 224, 3)\n",
      "Dimesiones de entrenamiento Y: (2039,)\n",
      "Dimesiones de test X: (339, 224, 224, 3)\n",
      "Dimesiones de test Y: (339,)\n",
      "Dimesiones de validacion X: (678, 224, 224, 3)\n",
      "Dimesiones de validacion Y: (678,)\n"
     ]
    }
   ],
   "source": [
    "# Análisis del conjunto de datos cargado\n",
    "print(\"Dimesiones de entrenamiento X: {}\".format(fold0_train_x.shape))\n",
    "print(\"Dimesiones de entrenamiento Y: {}\".format(fold0_train_y.shape))\n",
    "print(\"Dimesiones de test X: {}\".format(fold0_test_x.shape))\n",
    "print(\"Dimesiones de test Y: {}\".format(fold0_test_y.shape))\n",
    "print(\"Dimesiones de validacion X: {}\".format(fold0_valid_x.shape))\n",
    "print(\"Dimesiones de validacion Y: {}\".format(fold0_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos una muestra de las imagenes capturadas\n",
    "plt.figure(figsize=(20,20), dpi = 300)\n",
    "for i in range(5):\n",
    "  img = fold0_test_x[i]\n",
    "  plt.subplot(2,11, 1+i), plt.imshow(img[:,:,::-1])\n",
    "  plt.title(labels[fold0_test_y[i]])\n",
    "  plt.axis('off')\n",
    "  img = fold0_test_x[-i-1]\n",
    "  plt.subplot(2,11, 10-i), plt.imshow(img[:,:,::-1])\n",
    "  plt.title(labels[fold0_test_y[-i-1]])\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizamos los valores de las imagenes\n",
    "def normalize_images(images_list):\n",
    "    images_list_norm = images_list.astype('float32')\n",
    "    images_list_norm = images_list_norm / 255.0\n",
    "    return images_list_norm\n",
    "\n",
    "fold0_train_x_norm = normalize_images(fold0_train_x)\n",
    "fold0_test_x_norm = normalize_images(fold0_test_x)\n",
    "fold0_valid_x_norm = normalize_images(fold0_valid_x)\n",
    "# labels, fold0_train_y_norm = np.unique(fold0_train_y, return_inverse=True)\n",
    "# _, fold0_test_y_norm = np.unique(fold0_test_y, return_inverse=True)\n",
    "# _, fold0_valid_y_norm = np.unique(fold0_valid_y, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VGG16(model_name, fold_path, model_path):\n",
    "  inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "  head_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
    "\n",
    "  head_model.trainable = True\n",
    "\n",
    "  head_model = head_model(inputs, training = True)\n",
    "  head_model = tf.keras.layers.Flatten()(head_model)\n",
    "  head_model = tf.keras.layers.Dense(256, activation='relu')(head_model)\n",
    "  output = Dense(2, activation='softmax')(head_model)\n",
    "  model4 = Model(inputs=inputs, outputs = output)\n",
    "\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest'\n",
    "  )\n",
    "\n",
    "  validation_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  # Note that the validation data should not be augmented!\n",
    "  train_generator = train_datagen.flow_from_directory(fold_path + '/Train',\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(224, 224))     \n",
    "\n",
    "  validation_generator =  validation_datagen.flow_from_directory(fold_path + '/Valid',\n",
    "                                                          batch_size=32,\n",
    "                                                          class_mode  = 'categorical',\n",
    "                                                          target_size = (224, 224))\n",
    "\n",
    "  # compilamos el modelo y lo entrenamos\n",
    "  model4.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=Adam(learning_rate=0.0001),\n",
    "                metrics=[tfa.metrics.F1Score(num_classes=2, average='micro'), 'accuracy'])\n",
    "  \n",
    "  return model4, train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2039 images belonging to 2 classes.\n",
      "Found 678 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path4 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel_VGG16/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_VGG16\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model4, train_generator, validation_generator \u001b[39m=\u001b[39m create_VGG16(model_name, \u001b[39m'\u001b[39;49m\u001b[39mFold0\u001b[39;49m\u001b[39m'\u001b[39;49m, model_path4)\n\u001b[1;32m      4\u001b[0m model4\u001b[39m.\u001b[39msummary()\n\u001b[1;32m      6\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n",
      "Cell \u001b[0;32mIn [14], line 40\u001b[0m, in \u001b[0;36mcreate_VGG16\u001b[0;34m(model_name, fold_path, model_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m validation_generator \u001b[39m=\u001b[39m  validation_datagen\u001b[39m.\u001b[39mflow_from_directory(fold_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Valid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     33\u001b[0m                                                         batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     34\u001b[0m                                                         class_mode  \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m                                                         target_size \u001b[39m=\u001b[39m (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\n\u001b[1;32m     37\u001b[0m \u001b[39m# compilamos el modelo y lo entrenamos\u001b[39;00m\n\u001b[1;32m     38\u001b[0m model4\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     39\u001b[0m               optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m---> 40\u001b[0m               metrics\u001b[39m=\u001b[39m[tfa\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mF1Score(num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m model4, train_generator, validation_generator\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfa' is not defined"
     ]
    }
   ],
   "source": [
    "model_path4 = 'model_VGG16/'\n",
    "model_name = \"model_VGG16\"\n",
    "model4, train_generator, validation_generator = create_VGG16(model_name, 'Fold0', model_path4)\n",
    "model4.summary()\n",
    "\n",
    "batch_size = 32\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "# generamos un monitor para el earlystop cuando el modelo este entrenado\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, min_delta=0.001)\n",
    "# generamos el callback de guardado del modelo\n",
    "filepath = model_path4 + model_name + \"_best.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model4_history = model4.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch= steps_per_epoch,\n",
    "    epochs= 100,\n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    validation_data= validation_generator,\n",
    "    validation_steps= validation_steps\n",
    ")\n",
    "np.save(model_path4 + '{}-History.npy'.format(\"Model4\"), model4_history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b34ee0fcddae15d7a2710695e852170958f79b691c1258578475f546b8c6cbd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
