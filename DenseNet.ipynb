{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdLas17wtpzTohuBNCzfbo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoNGoL/tfm_breast_cancer_detection/blob/main/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F6_OPYawN89",
        "outputId": "6370ef7d-5dd4-437b-c376-89102e073be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tfa-nightly\n",
            "  Downloading tfa_nightly-0.19.0.dev20221011203729-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tfa-nightly) (3.0.9)\n",
            "Installing collected packages: tfa-nightly\n",
            "Successfully installed tfa-nightly-0.19.0.dev20221011203729\n",
            "2.9.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-1045d80ee632>:41: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "True\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/TFM/DenseNet_models\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tfa-nightly\n",
        "#importacion de librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# config = tf.compat.v1.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# sess = tf.compat.v1.Session(config=config)\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from keras.models import *\n",
        "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import densenet\n",
        "from keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import PIL\n",
        "import glob\n",
        "from io import BytesIO\n",
        "import timeit\n",
        "import os\n",
        "import warnings\n",
        "import statistics\n",
        "# warnings.filterwarnings('ignore')\n",
        "# from tensorflow.python.keras.applications.efficientnet import EfficientNetB0\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "print(tf.test.is_gpu_available())\n",
        "# tf.config.experimental.set_memory_growth = True\n",
        "# %cd /home/fundamentia/Dropbox/Master/Asignaturas/Deep Learning/PRA1/archive/practica_DL_UOC_2022\n",
        "def freeze_layers(model):\n",
        "    for i in model.layers:\n",
        "        i.trainable = False\n",
        "        if isinstance(i, Model):\n",
        "            freeze_layers(i)\n",
        "    return model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/TFM/DenseNet_models/\n",
        "%cp -r /content/drive/MyDrive/TFM/Fold10 /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_DenseNet(model_name, fold_path, model_path, optimizer=Adam(learning_rate=0.0001)):\n",
        "  inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "  head_model = densenet.DenseNet121(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
        "\n",
        "  head_model.trainable = True\n",
        "\n",
        "  head_model = head_model(inputs, training = True)\n",
        "  head_model = tf.keras.layers.Flatten()(head_model)\n",
        "  head_model = tf.keras.layers.Dense(256, activation='relu')(head_model)\n",
        "\n",
        "  # head_model = tf.keras.layers.Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01), activation='relu')(head_model)\n",
        "  # # head_model = Activation('relu')(head_model)\n",
        "  # head_model = tf.keras.layers.Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01), activation='relu')(head_model)\n",
        "  # # head_model = Activation('relu')(head_model)\n",
        "  output = Dense(3, activation='softmax')(head_model)\n",
        "  model4 = Model(inputs=inputs, outputs = output)\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  validation_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Note that the validation data should not be augmented!\n",
        "  train_generator = train_datagen.flow_from_directory(fold_path + '/Train',\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(224, 224))     \n",
        "\n",
        "  validation_generator =  validation_datagen.flow_from_directory(fold_path + '/Valid',\n",
        "                                                          batch_size=32,\n",
        "                                                          class_mode  = 'categorical',\n",
        "                                                          target_size = (224, 224))\n",
        "\n",
        "  # compilamos el modelo y lo entrenamos\n",
        "  model4.compile(loss=\"categorical_crossentropy\", \n",
        "                optimizer=optimizer,\n",
        "                metrics=[tfa.metrics.F1Score(num_classes=3, average='micro'), 'accuracy'])\n",
        "  \n",
        "  return model4, train_generator, validation_generator"
      ],
      "metadata": {
        "id": "iR-ouHcgydmf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_DenseNet_model(model4, train_generator, validation_generator, model_path, model_name, epochs=100):\n",
        "  batch_size = 64\n",
        "  steps_per_epoch = train_generator.n // batch_size\n",
        "  validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "  # generamos un monitor para el earlystop cuando el modelo este entrenado\n",
        "  early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, min_delta=0.001)\n",
        "  # generamos el callback de guardado del modelo\n",
        "  filepath = model_path + model_name + \"_best.hdf5\"\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "  model4_history = model4.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch = steps_per_epoch,\n",
        "      epochs = epochs,\n",
        "      callbacks = [early_stop, checkpoint], \n",
        "      validation_data = validation_generator,\n",
        "      validation_steps = validation_steps\n",
        "  )\n",
        "  return model4, model4_history"
      ],
      "metadata": {
        "id": "0E6X2Yj1yg-L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [{'type':Adam, 'name': 'Adam'}, {'type':SGD, 'name': 'SGD'}, {'type':Adagrad, 'name': 'Adagrad'}]\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "\n",
        "model_path4 = '/content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/'\n",
        "i = 0\n",
        "for opt in optimizers:\n",
        "  for lr in lrs: \n",
        "    print(opt['name'])\n",
        "    if  i < 5:\n",
        "      i+=1\n",
        "      continue\n",
        "    model_name = \"model_DenseNet_{}_{}\".format(opt['name'], lr)\n",
        "    model4, train_generator, validation_generator = create_DenseNet(model_name, '/content/Fold10', model_path4, opt['type'](learning_rate=lr))\n",
        "    model4.summary()\n",
        "\n",
        "    model4, model4_history = train_DenseNet_model(model4, train_generator, validation_generator, model_path4, model_name, 40)\n",
        "    np.save(model_path4 + '{}-History.npy'.format(model_name), model4_history.history)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4qV_5CEykGW",
        "outputId": "892327e5-3c6d-446d-be90-19bc17fe6a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam\n",
            "Adam\n",
            "Adam\n",
            "SGD\n",
            "SGD\n",
            "SGD\n",
            "Found 3190 images belonging to 3 classes.\n",
            "Found 1060 images belonging to 3 classes.\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               12845312  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,883,587\n",
            "Trainable params: 19,799,939\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.9966 - f1_score: 0.5783 - accuracy: 0.5783\n",
            "Epoch 1: val_f1_score improved from -inf to 0.64844, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 39s 615ms/step - loss: 0.9966 - f1_score: 0.5783 - accuracy: 0.5783 - val_loss: 0.7806 - val_f1_score: 0.6484 - val_accuracy: 0.6484\n",
            "Epoch 2/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6847 - f1_score: 0.6855 - accuracy: 0.6855\n",
            "Epoch 2: val_f1_score improved from 0.64844 to 0.70508, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 28s 574ms/step - loss: 0.6847 - f1_score: 0.6855 - accuracy: 0.6855 - val_loss: 0.6869 - val_f1_score: 0.7051 - val_accuracy: 0.7051\n",
            "Epoch 3/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5739 - f1_score: 0.7311 - accuracy: 0.7311\n",
            "Epoch 3: val_f1_score improved from 0.70508 to 0.75195, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 26s 535ms/step - loss: 0.5739 - f1_score: 0.7311 - accuracy: 0.7311 - val_loss: 0.5429 - val_f1_score: 0.7520 - val_accuracy: 0.7520\n",
            "Epoch 4/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5414 - f1_score: 0.7542 - accuracy: 0.7542\n",
            "Epoch 4: val_f1_score improved from 0.75195 to 0.77148, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 27s 553ms/step - loss: 0.5414 - f1_score: 0.7542 - accuracy: 0.7542 - val_loss: 0.5270 - val_f1_score: 0.7715 - val_accuracy: 0.7715\n",
            "Epoch 5/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5199 - f1_score: 0.7423 - accuracy: 0.7423\n",
            "Epoch 5: val_f1_score did not improve from 0.77148\n",
            "49/49 [==============================] - 27s 539ms/step - loss: 0.5199 - f1_score: 0.7423 - accuracy: 0.7423 - val_loss: 0.5380 - val_f1_score: 0.7500 - val_accuracy: 0.7500\n",
            "Epoch 6/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4983 - f1_score: 0.7587 - accuracy: 0.7587\n",
            "Epoch 6: val_f1_score improved from 0.77148 to 0.78320, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 26s 535ms/step - loss: 0.4983 - f1_score: 0.7587 - accuracy: 0.7587 - val_loss: 0.4886 - val_f1_score: 0.7832 - val_accuracy: 0.7832\n",
            "Epoch 7/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4734 - f1_score: 0.7787 - accuracy: 0.7787\n",
            "Epoch 7: val_f1_score improved from 0.78320 to 0.83789, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 27s 546ms/step - loss: 0.4734 - f1_score: 0.7787 - accuracy: 0.7787 - val_loss: 0.3741 - val_f1_score: 0.8379 - val_accuracy: 0.8379\n",
            "Epoch 8/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4963 - f1_score: 0.7462 - accuracy: 0.7462\n",
            "Epoch 8: val_f1_score did not improve from 0.83789\n",
            "49/49 [==============================] - 26s 532ms/step - loss: 0.4963 - f1_score: 0.7462 - accuracy: 0.7462 - val_loss: 0.4272 - val_f1_score: 0.8027 - val_accuracy: 0.8027\n",
            "Epoch 9/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4266 - f1_score: 0.7978 - accuracy: 0.7978\n",
            "Epoch 9: val_f1_score did not improve from 0.83789\n",
            "49/49 [==============================] - 25s 504ms/step - loss: 0.4266 - f1_score: 0.7978 - accuracy: 0.7978 - val_loss: 0.3928 - val_f1_score: 0.8203 - val_accuracy: 0.8203\n",
            "Epoch 10/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4584 - f1_score: 0.7843 - accuracy: 0.7843\n",
            "Epoch 10: val_f1_score did not improve from 0.83789\n",
            "49/49 [==============================] - 25s 503ms/step - loss: 0.4584 - f1_score: 0.7843 - accuracy: 0.7843 - val_loss: 0.3951 - val_f1_score: 0.8223 - val_accuracy: 0.8223\n",
            "Epoch 11/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4161 - f1_score: 0.7959 - accuracy: 0.7959\n",
            "Epoch 11: val_f1_score did not improve from 0.83789\n",
            "49/49 [==============================] - 25s 505ms/step - loss: 0.4161 - f1_score: 0.7959 - accuracy: 0.7959 - val_loss: 0.3906 - val_f1_score: 0.8223 - val_accuracy: 0.8223\n",
            "Epoch 12/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3809 - f1_score: 0.8195 - accuracy: 0.8195\n",
            "Epoch 12: val_f1_score did not improve from 0.83789\n",
            "49/49 [==============================] - 26s 535ms/step - loss: 0.3809 - f1_score: 0.8195 - accuracy: 0.8195 - val_loss: 0.3848 - val_f1_score: 0.8242 - val_accuracy: 0.8242\n",
            "Epoch 13/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4126 - f1_score: 0.8055 - accuracy: 0.8055\n",
            "Epoch 13: val_f1_score improved from 0.83789 to 0.84961, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_SGD_0.0001_best.hdf5\n",
            "49/49 [==============================] - 26s 531ms/step - loss: 0.4126 - f1_score: 0.8055 - accuracy: 0.8055 - val_loss: 0.3435 - val_f1_score: 0.8496 - val_accuracy: 0.8496\n",
            "Epoch 14/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3723 - f1_score: 0.8267 - accuracy: 0.8267\n",
            "Epoch 14: val_f1_score did not improve from 0.84961\n",
            "49/49 [==============================] - 26s 531ms/step - loss: 0.3723 - f1_score: 0.8267 - accuracy: 0.8267 - val_loss: 0.3803 - val_f1_score: 0.8262 - val_accuracy: 0.8262\n",
            "Epoch 15/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3971 - f1_score: 0.7985 - accuracy: 0.7985\n",
            "Epoch 15: val_f1_score did not improve from 0.84961\n",
            "49/49 [==============================] - 25s 507ms/step - loss: 0.3971 - f1_score: 0.7985 - accuracy: 0.7985 - val_loss: 0.3576 - val_f1_score: 0.8438 - val_accuracy: 0.8438\n",
            "Epoch 16/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3607 - f1_score: 0.8196 - accuracy: 0.8196\n",
            "Epoch 16: val_f1_score did not improve from 0.84961\n",
            "49/49 [==============================] - 25s 503ms/step - loss: 0.3607 - f1_score: 0.8196 - accuracy: 0.8196 - val_loss: 0.3455 - val_f1_score: 0.8359 - val_accuracy: 0.8359\n",
            "Epoch 17/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3919 - f1_score: 0.8208 - accuracy: 0.8208\n",
            "Epoch 17: val_f1_score did not improve from 0.84961\n",
            "49/49 [==============================] - 27s 538ms/step - loss: 0.3919 - f1_score: 0.8208 - accuracy: 0.8208 - val_loss: 0.3346 - val_f1_score: 0.8418 - val_accuracy: 0.8418\n",
            "Epoch 18/40\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3687 - f1_score: 0.8261 - accuracy: 0.8261\n",
            "Epoch 18: val_f1_score did not improve from 0.84961\n",
            "49/49 [==============================] - 25s 503ms/step - loss: 0.3687 - f1_score: 0.8261 - accuracy: 0.8261 - val_loss: 0.3518 - val_f1_score: 0.8477 - val_accuracy: 0.8477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path4 = '/content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/'\n",
        "optimizers = [{'type':Adam, 'name': 'Adam'}, {'type':SGD, 'name': 'SGD'}, {'type':Adagrad, 'name': 'Adagrad'}]\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "head_model = densenet.DenseNet121(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
        "\n",
        "head_model.trainable = True\n",
        "\n",
        "head_model = head_model(inputs, training = True)\n",
        "head_model = tf.keras.layers.Flatten()(head_model)\n",
        "head_model = tf.keras.layers.Dense(256, activation='relu')(head_model)\n",
        "# output = Dense(2, activation='softmax')(head_model)\n",
        "output = Dense(3, activation='softmax')(head_model)\n",
        "model4 = Model(inputs=inputs, outputs = output)\n",
        "\n",
        "for opt in optimizers:\n",
        "  for lr in lrs: \n",
        "    name = \"model_DenseNet_{}_{}\".format(opt['name'], lr)\n",
        "    print(name)\n",
        "    model4_history = np.load(model_path4 + '{}-History.npy'.format(name),allow_pickle='TRUE').item()\n",
        "    # model4 = keras.models.load_model(model_path4 + name +\"_best.hdf5\")\n",
        "\n",
        "    model4.load_weights(model_path4 + \"{}_best.hdf5\".format(name))\n",
        "    model4.compile(loss=\"categorical_crossentropy\", \n",
        "                  optimizer=opt['type'](learning_rate=lr),\n",
        "                  metrics=[tfa.metrics.F1Score(num_classes=3, average='micro'), 'accuracy'])\n",
        "\n",
        "    # Visualizamos la evolución de la accuracy\n",
        "    plt.plot(model4_history['accuracy'])\n",
        "    plt.plot(model4_history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(model4_history['f1_score'])\n",
        "    plt.plot(model4_history['val_f1_score'])\n",
        "    plt.title('f1 score')\n",
        "    plt.ylabel('f1 score')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(model4_history['loss'])\n",
        "    plt.plot(model4_history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator =  test_datagen.flow_from_directory('/content/Fold10/Test',\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode  = 'categorical',\n",
        "                                                              target_size = (224, 224), shuffle=False)\n",
        "\n",
        "    test_lost, test_f1, test_acc = model4.evaluate(test_generator)\n",
        "    print (\"Test f1:\", test_f1)\n",
        "    print (\"Test Accuracy:\", test_acc)\n",
        "\n",
        "    test_generator.reset()\n",
        "    predict = model4.predict(test_generator)\n",
        "    y_pred = np.rint(predict)\n",
        "    y_true = test_generator.classes\n",
        "    pred2 = []\n",
        "    for p in y_pred:\n",
        "      pred2.append(np.argmax(p))\n",
        "\n",
        "    matrix = confusion_matrix(y_true, pred2)\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=['Calc', 'Mass', 'Otros'])\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "    plt.title(\"Matriz de confusión\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A1Ti2Kp_ysWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}