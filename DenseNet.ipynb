{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQrYkFU/zesc0JeeqXxoQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoNGoL/tfm_breast_cancer_detection/blob/main/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F6_OPYawN89",
        "outputId": "f99f8398-62cc-44a5-fb05-0692e214daf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tfa-nightly\n",
            "  Downloading tfa_nightly-0.19.0.dev20221011203729-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tfa-nightly) (3.0.9)\n",
            "Installing collected packages: tfa-nightly\n",
            "Successfully installed tfa-nightly-0.19.0.dev20221011203729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-1045d80ee632>:41: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "True\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/TFM/DenseNet_models\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tfa-nightly\n",
        "#importacion de librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# config = tf.compat.v1.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# sess = tf.compat.v1.Session(config=config)\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from keras.models import *\n",
        "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import densenet\n",
        "from keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import PIL\n",
        "import glob\n",
        "from io import BytesIO\n",
        "import timeit\n",
        "import os\n",
        "import warnings\n",
        "import statistics\n",
        "# warnings.filterwarnings('ignore')\n",
        "# from tensorflow.python.keras.applications.efficientnet import EfficientNetB0\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "print(tf.test.is_gpu_available())\n",
        "# tf.config.experimental.set_memory_growth = True\n",
        "# %cd /home/fundamentia/Dropbox/Master/Asignaturas/Deep Learning/PRA1/archive/practica_DL_UOC_2022\n",
        "def freeze_layers(model):\n",
        "    for i in model.layers:\n",
        "        i.trainable = False\n",
        "        if isinstance(i, Model):\n",
        "            freeze_layers(i)\n",
        "    return model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/TFM/DenseNet_models/\n",
        "%cp -r /content/drive/MyDrive/TFM/Fold10 /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_DenseNet(model_name, fold_path, model_path, optimizer=Adam(learning_rate=0.0001)):\n",
        "  inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "  head_model = densenet.DenseNet121(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
        "\n",
        "  head_model.trainable = True\n",
        "\n",
        "  head_model = head_model(inputs, training = True)\n",
        "  head_model = tf.keras.layers.Flatten()(head_model)\n",
        "  head_model = tf.keras.layers.Dense(256, activation='relu')(head_model)\n",
        "\n",
        "  # head_model = tf.keras.layers.Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01), activation='relu')(head_model)\n",
        "  # # head_model = Activation('relu')(head_model)\n",
        "  # head_model = tf.keras.layers.Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01), activation='relu')(head_model)\n",
        "  # # head_model = Activation('relu')(head_model)\n",
        "  output = Dense(3, activation='softmax')(head_model)\n",
        "  model4 = Model(inputs=inputs, outputs = output)\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  validation_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Note that the validation data should not be augmented!\n",
        "  train_generator = train_datagen.flow_from_directory(fold_path + '/Train',\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(224, 224))     \n",
        "\n",
        "  validation_generator =  validation_datagen.flow_from_directory(fold_path + '/Valid',\n",
        "                                                          batch_size=32,\n",
        "                                                          class_mode  = 'categorical',\n",
        "                                                          target_size = (224, 224))\n",
        "\n",
        "  # compilamos el modelo y lo entrenamos\n",
        "  model4.compile(loss=\"categorical_crossentropy\", \n",
        "                optimizer=optimizer,\n",
        "                metrics=[tfa.metrics.F1Score(num_classes=3, average='micro'), 'accuracy'])\n",
        "  \n",
        "  return model4, train_generator, validation_generator"
      ],
      "metadata": {
        "id": "iR-ouHcgydmf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_DenseNet_model(model4, train_generator, validation_generator, model_path, model_name, epochs=100):\n",
        "  batch_size = 32\n",
        "  steps_per_epoch = train_generator.n // batch_size\n",
        "  validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "  # generamos un monitor para el earlystop cuando el modelo este entrenado\n",
        "  early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, min_delta=0.001)\n",
        "  # generamos el callback de guardado del modelo\n",
        "  filepath = model_path + model_name + \"_best.hdf5\"\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "  model4_history = model4.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch = steps_per_epoch,\n",
        "      epochs = epochs,\n",
        "      callbacks = [early_stop, checkpoint], \n",
        "      validation_data = validation_generator,\n",
        "      validation_steps = validation_steps\n",
        "  )\n",
        "  return model4, model4_history"
      ],
      "metadata": {
        "id": "0E6X2Yj1yg-L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [{'type':Adam, 'name': 'Adam'}, {'type':SGD, 'name': 'SGD'}, {'type':Adagrad, 'name': 'Adagrad'}]\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "\n",
        "model_path4 = '/content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/'\n",
        "for opt in optimizers:\n",
        "  for lr in lrs: \n",
        "    print(opt['name'])\n",
        "    model_name = \"model_DenseNet_{}_{}\".format(opt['name'], lr)\n",
        "    model4, train_generator, validation_generator = create_DenseNet(model_name, '/content/Fold10', model_path4, opt['type'](learning_rate=0.0001))\n",
        "    model4.summary()\n",
        "\n",
        "    model4, model4_history = train_DenseNet_model(model4, train_generator, validation_generator, model_path4, model_name, 40)\n",
        "    np.save(model_path4 + '{}-History.npy'.format(model_name), model4_history.history)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "M4qV_5CEykGW",
        "outputId": "e9f5e854-fd2c-475d-8ed3-eb7302b13670"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam\n",
            "Found 3190 images belonging to 3 classes.\n",
            "Found 1060 images belonging to 3 classes.\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               12845312  \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,883,587\n",
            "Trainable params: 19,799,939\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5350 - f1_score: 0.7964 - accuracy: 0.7964\n",
            "Epoch 1: val_f1_score improved from -inf to 0.89299, saving model to /content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/model_DenseNet_Adam_0.01_best.hdf5\n",
            "99/99 [==============================] - 80s 572ms/step - loss: 0.5350 - f1_score: 0.7964 - accuracy: 0.7964 - val_loss: 0.2429 - val_f1_score: 0.8930 - val_accuracy: 0.8930\n",
            "Epoch 2/40\n",
            "30/99 [========>.....................] - ETA: 32s - loss: 0.2416 - f1_score: 0.8895 - accuracy: 0.8895"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-924ad8a690a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel4_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_DenseNet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{}-History.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel4_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e598a293ba7d>\u001b[0m in \u001b[0;36mtrain_DenseNet_model\u001b[0;34m(model4, train_generator, validation_generator, model_path, model_name, epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   )\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel4_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path4 = '/content/drive/MyDrive/TFM/DenseNet_models/model_DenseNet_hyper/'\n",
        "optimizers = [{'type':Adam, 'name': 'Adam'}, {'type':SGD, 'name': 'SGD'}, {'type':Adagrad, 'name': 'Adagrad'}]\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "head_model = densenet.DenseNet121(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
        "\n",
        "head_model.trainable = True\n",
        "\n",
        "head_model = head_model(inputs, training = True)\n",
        "head_model = tf.keras.layers.Flatten()(head_model)\n",
        "head_model = tf.keras.layers.Dense(256, activation='relu')(head_model)\n",
        "# output = Dense(2, activation='softmax')(head_model)\n",
        "output = Dense(3, activation='softmax')(head_model)\n",
        "model4 = Model(inputs=inputs, outputs = output)\n",
        "\n",
        "for opt in optimizers:\n",
        "  for lr in lrs: \n",
        "    name = \"model_DenseNet_{}_{}\".format(opt['name'], lr)\n",
        "    print(name)\n",
        "    model4_history = np.load(model_path4 + '{}-History.npy'.format(name),allow_pickle='TRUE').item()\n",
        "    # model4 = keras.models.load_model(model_path4 + name +\"_best.hdf5\")\n",
        "\n",
        "    model4.load_weights(model_path4 + \"{}_best.hdf5\".format(name))\n",
        "    model4.compile(loss=\"categorical_crossentropy\", \n",
        "                  optimizer=opt['type'](learning_rate=lr),\n",
        "                  metrics=[tfa.metrics.F1Score(num_classes=2, average='micro'), 'accuracy'])\n",
        "\n",
        "    # Visualizamos la evolución de la accuracy\n",
        "    plt.plot(model4_history['accuracy'])\n",
        "    plt.plot(model4_history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(model4_history['f1_score'])\n",
        "    plt.plot(model4_history['val_f1_score'])\n",
        "    plt.title('f1 score')\n",
        "    plt.ylabel('f1 score')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(model4_history['loss'])\n",
        "    plt.plot(model4_history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator =  test_datagen.flow_from_directory('/content/Fold10/Test',\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode  = 'categorical',\n",
        "                                                              target_size = (224, 224), shuffle=False)\n",
        "\n",
        "    test_lost, test_f1, test_acc = model4.evaluate(test_generator)\n",
        "    print (\"Test f1:\", test_f1)\n",
        "    print (\"Test Accuracy:\", test_acc)\n",
        "\n",
        "    test_generator.reset()\n",
        "    predict = model4.predict(test_generator)\n",
        "    y_pred = np.rint(predict)\n",
        "    y_true = test_generator.classes\n",
        "    pred2 = []\n",
        "    for p in y_pred:\n",
        "      pred2.append(np.argmax(p))\n",
        "\n",
        "    matrix = confusion_matrix(y_true, pred2)\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=['Calc', 'Mass', 'Otros'])\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "    plt.title(\"Matriz de confusión\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A1Ti2Kp_ysWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}